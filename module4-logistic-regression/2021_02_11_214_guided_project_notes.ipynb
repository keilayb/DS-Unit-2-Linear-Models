{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IorwKysWC9zl"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "\n",
    "# If you're on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
    "    !pip install category_encoders==2.*\n",
    "\n",
    "# If you're working locally:\n",
    "else:\n",
    "    DATA_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9q1YdYUAGho",
    "outputId": "ae09c1d4-bafe-43e7-ccca-4c12a13b8e3c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff_NZhdHCvfc"
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 1, Module 4*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0tT4qPmCzUF"
   },
   "source": [
    "# Part 1: Sprint Challenge Practice\n",
    "\n",
    "- Can I import a CSV file into a DataFrame?\n",
    "- Can I create a scatter plot?\n",
    "- Can I split a DataFrame into a target vector and feature matrix?\n",
    "- Can I split a dataset into a training set and a test set?\n",
    "- Can I establish the baseline mean absolute error for a regression problem?\n",
    "- Can I combine transformers with a predictor using a pipeline?\n",
    "- Can I build a linear regresion model and a ridge regression model?\n",
    "- Can I evaluate a model using common metrics like mean absolute error, root mean squared error, and R^2?\n",
    "- If given a feature matrix, can I use my model to create a list of predictions?\n",
    "- Can I create a horizontal bar chart with the coefficients from a linear model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-sAbpUqC3dt"
   },
   "source": [
    "# Part 2: Pipelines and Plotting\n",
    "\n",
    "Let's revise [our work from yesterday](https://drive.google.com/file/d/1ZLdUeDkLQNxMJyvbyHfiAvyv-NXPICP9/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XD8xTT0yC-bq"
   },
   "source": [
    "# Part 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Cz8n4xnWmok"
   },
   "source": [
    "# I. Wrangle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMkDazfUzP_v"
   },
   "outputs": [],
   "source": [
    "def wrangle(filepath):\n",
    "  df = pd.read_csv(filepath, index_col = 'PassengerId')\n",
    "  df.drop(columns = ['Name', 'Ticket', 'Cabin'], inplace = True)\n",
    "  return df\n",
    "\n",
    "df = wrangle(DATA_PATH+'titanic/train.csv')\n",
    "X_test = wrangle(DATA_PATH+'titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQVuApzeV2Ic",
    "outputId": "7bd7d08c-9743-4d4a-c3b6-eddce0bf542d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Sex       891 non-null    object \n",
      " 3   Age       714 non-null    float64\n",
      " 4   SibSp     891 non-null    int64  \n",
      " 5   Parch     891 non-null    int64  \n",
      " 6   Fare      891 non-null    float64\n",
      " 7   Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0eZCdJnWPQB",
    "outputId": "233c6c03-acbd-4111-d103-10fd9c3bb3df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    418 non-null    int64  \n",
      " 1   Sex       418 non-null    object \n",
      " 2   Age       332 non-null    float64\n",
      " 3   SibSp     418 non-null    int64  \n",
      " 4   Parch     418 non-null    int64  \n",
      " 5   Fare      417 non-null    float64\n",
      " 6   Embarked  418 non-null    object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 26.1+ KB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gE8VLgUaW_S3"
   },
   "source": [
    "The test set does not contain the target.\n",
    "\n",
    "Therefore, we cannot actually check our metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vy-2aFoDXrar"
   },
   "source": [
    "## II. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARITmeldXfvP"
   },
   "outputs": [],
   "source": [
    "# Split TV from our FM\n",
    "target = 'Survived'\n",
    "y = df[target]\n",
    "X = df.drop(columns=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xTafalS_8V1"
   },
   "source": [
    "Since there's no time series component, we should do a randomized train-validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbtV3_BuX2oL"
   },
   "outputs": [],
   "source": [
    "# Split our data into a TRAINING set and a VALIDATION set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQ0X5kSGZtge"
   },
   "source": [
    "## III. Establish our baseline\n",
    "\n",
    "- This is a **classification problem**, so we look at the **majority class** to calculate baseline **accuracy score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MA4wM3F32s9O",
    "outputId": "379fc4db-68bb-47fe-a7c6-1c5e50bfa1a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy Score: 0.6235955056179775\n"
     ]
    }
   ],
   "source": [
    "print('Baseline Accuracy Score:',y_train.value_counts(normalize = True).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhN5A57katzk"
   },
   "source": [
    "## IV. Build Model\n",
    "\n",
    "- Why would regular linear regression not work here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "S_NcVWenARnb",
    "outputId": "712428b5-ff6c-4fb6-e0e8-78632f24ea1a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['Age'], df['Survived'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Survived');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSPWqMR6ieDZ"
   },
   "source": [
    "Logistic regression is used when we are answering a classification question.\n",
    "- Here we want to know: Did this person survive -- yes or no?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEbK3zKW80aN"
   },
   "source": [
    "What we need for our model pipeline:\n",
    "\n",
    "- `OneHotEncoder`\n",
    "- `SimpleImputer`\n",
    "- `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HWCW8vH18z_s",
    "outputId": "52eb929a-2c2e-4282-87ff-8048ed1a8066"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(\n",
    "    OneHotEncoder(use_cat_names = True),\n",
    "    SimpleImputer(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewFaW1p_etFX"
   },
   "source": [
    "## V. Check Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EhxohqPsesdf",
    "outputId": "5c016fa3-39b7-4bcd-9e5a-73805552b99d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8019662921348315\n",
      "Validation Accuracy: 0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy:', model.score(X_train, y_train))\n",
    "print('Validation Accuracy:', model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7TLpbAWc9yJ",
    "outputId": "609f7b6d-0f7e-494c-c514-d32c7ab31d06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what I would upload to Kaggle if I was doing a competition\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thg1Zh5MdHQC",
    "outputId": "610614c9-51bf-4d1c-f70e-a3eff0237d19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87998966, 0.12001034],\n",
       "       [0.56540169, 0.43459831],\n",
       "       [0.87052991, 0.12947009],\n",
       "       [0.88672331, 0.11327669],\n",
       "       [0.41529622, 0.58470378],\n",
       "       [0.84295034, 0.15704966],\n",
       "       [0.30957684, 0.69042316],\n",
       "       [0.8189231 , 0.1810769 ],\n",
       "       [0.21599336, 0.78400664],\n",
       "       [0.91748425, 0.08251575],\n",
       "       [0.89401077, 0.10598923],\n",
       "       [0.68998487, 0.31001513],\n",
       "       [0.08125443, 0.91874557],\n",
       "       [0.92081526, 0.07918474],\n",
       "       [0.15930328, 0.84069672],\n",
       "       [0.14551023, 0.85448977],\n",
       "       [0.7534408 , 0.2465592 ],\n",
       "       [0.81192954, 0.18807046],\n",
       "       [0.42125488, 0.57874512],\n",
       "       [0.37537433, 0.62462567],\n",
       "       [0.69255196, 0.30744804],\n",
       "       [0.84419823, 0.15580177],\n",
       "       [0.08625667, 0.91374333],\n",
       "       [0.4183106 , 0.5816894 ],\n",
       "       [0.08995342, 0.91004658],\n",
       "       [0.95213973, 0.04786027],\n",
       "       [0.04889841, 0.95110159],\n",
       "       [0.81845668, 0.18154332],\n",
       "       [0.65496883, 0.34503117],\n",
       "       [0.90341228, 0.09658772],\n",
       "       [0.88874201, 0.11125799],\n",
       "       [0.83150875, 0.16849125],\n",
       "       [0.52068463, 0.47931537],\n",
       "       [0.49307086, 0.50692914],\n",
       "       [0.5238068 , 0.4761932 ],\n",
       "       [0.80065094, 0.19934906],\n",
       "       [0.36976697, 0.63023303],\n",
       "       [0.31416645, 0.68583355],\n",
       "       [0.88050257, 0.11949743],\n",
       "       [0.8780403 , 0.1219597 ],\n",
       "       [0.89056538, 0.10943462],\n",
       "       [0.57971429, 0.42028571],\n",
       "       [0.92163372, 0.07836628],\n",
       "       [0.19625521, 0.80374479],\n",
       "       [0.1553686 , 0.8446314 ],\n",
       "       [0.88104156, 0.11895844],\n",
       "       [0.58240029, 0.41759971],\n",
       "       [0.86390692, 0.13609308],\n",
       "       [0.11395132, 0.88604868],\n",
       "       [0.47435053, 0.52564947],\n",
       "       [0.58446252, 0.41553748],\n",
       "       [0.67600529, 0.32399471],\n",
       "       [0.26455571, 0.73544429],\n",
       "       [0.11640554, 0.88359446],\n",
       "       [0.6912302 , 0.3087698 ],\n",
       "       [0.9240611 , 0.0759389 ],\n",
       "       [0.90815292, 0.09184708],\n",
       "       [0.88113545, 0.11886455],\n",
       "       [0.91629285, 0.08370715],\n",
       "       [0.03387288, 0.96612712],\n",
       "       [0.85462376, 0.14537624],\n",
       "       [0.78774257, 0.21225743],\n",
       "       [0.85823382, 0.14176618],\n",
       "       [0.2624061 , 0.7375939 ],\n",
       "       [0.37591647, 0.62408353],\n",
       "       [0.18993804, 0.81006196],\n",
       "       [0.24057176, 0.75942824],\n",
       "       [0.68470733, 0.31529267],\n",
       "       [0.48301061, 0.51698939],\n",
       "       [0.19639534, 0.80360466],\n",
       "       [0.27372412, 0.72627588],\n",
       "       [0.86839949, 0.13160051],\n",
       "       [0.36650985, 0.63349015],\n",
       "       [0.46566967, 0.53433033],\n",
       "       [0.03865064, 0.96134936],\n",
       "       [0.3495778 , 0.6504222 ],\n",
       "       [0.89396314, 0.10603686],\n",
       "       [0.26320864, 0.73679136],\n",
       "       [0.77820364, 0.22179636],\n",
       "       [0.27372412, 0.72627588],\n",
       "       [0.80607282, 0.19392718],\n",
       "       [0.74192878, 0.25807122],\n",
       "       [0.70821018, 0.29178982],\n",
       "       [0.89401077, 0.10598923],\n",
       "       [0.7238202 , 0.2761798 ],\n",
       "       [0.87781558, 0.12218442],\n",
       "       [0.29119823, 0.70880177],\n",
       "       [0.29621767, 0.70378233],\n",
       "       [0.30640756, 0.69359244],\n",
       "       [0.69748551, 0.30251449],\n",
       "       [0.38189173, 0.61810827],\n",
       "       [0.89404806, 0.10595194],\n",
       "       [0.12532645, 0.87467355],\n",
       "       [0.89396314, 0.10603686],\n",
       "       [0.4420043 , 0.5579957 ],\n",
       "       [0.88108568, 0.11891432],\n",
       "       [0.29249005, 0.70750995],\n",
       "       [0.89262847, 0.10737153],\n",
       "       [0.3085378 , 0.6914622 ],\n",
       "       [0.90317515, 0.09682485],\n",
       "       [0.10094646, 0.89905354],\n",
       "       [0.80432884, 0.19567116],\n",
       "       [0.86390692, 0.13609308],\n",
       "       [0.88408598, 0.11591402],\n",
       "       [0.28300339, 0.71699661],\n",
       "       [0.88507681, 0.11492319],\n",
       "       [0.83235298, 0.16764702],\n",
       "       [0.86390692, 0.13609308],\n",
       "       [0.89375831, 0.10624169],\n",
       "       [0.71566057, 0.28433943],\n",
       "       [0.75765022, 0.24234978],\n",
       "       [0.30638733, 0.69361267],\n",
       "       [0.06921019, 0.93078981],\n",
       "       [0.24357797, 0.75642203],\n",
       "       [0.15127683, 0.84872317],\n",
       "       [0.83750051, 0.16249949],\n",
       "       [0.8469222 , 0.1530778 ],\n",
       "       [0.27625736, 0.72374264],\n",
       "       [0.48107077, 0.51892923],\n",
       "       [0.23258904, 0.76741096],\n",
       "       [0.12578204, 0.87421796],\n",
       "       [0.89430538, 0.10569462],\n",
       "       [0.08125889, 0.91874111],\n",
       "       [0.89004383, 0.10995617],\n",
       "       [0.86390692, 0.13609308],\n",
       "       [0.31295597, 0.68704403],\n",
       "       [0.87170212, 0.12829788],\n",
       "       [0.42733189, 0.57266811],\n",
       "       [0.83227859, 0.16772141],\n",
       "       [0.87793695, 0.12206305],\n",
       "       [0.90061947, 0.09938053],\n",
       "       [0.63821724, 0.36178276],\n",
       "       [0.4866679 , 0.5133321 ],\n",
       "       [0.88059008, 0.11940992],\n",
       "       [0.92569574, 0.07430426],\n",
       "       [0.87800531, 0.12199469],\n",
       "       [0.8349979 , 0.1650021 ],\n",
       "       [0.75762157, 0.24237843],\n",
       "       [0.32718523, 0.67281477],\n",
       "       [0.96773355, 0.03226645],\n",
       "       [0.61823994, 0.38176006],\n",
       "       [0.06600684, 0.93399316],\n",
       "       [0.67401724, 0.32598276],\n",
       "       [0.76043968, 0.23956032],\n",
       "       [0.66434359, 0.33565641],\n",
       "       [0.95279578, 0.04720422],\n",
       "       [0.55949476, 0.44050524],\n",
       "       [0.87160945, 0.12839055],\n",
       "       [0.57971429, 0.42028571],\n",
       "       [0.83677009, 0.16322991],\n",
       "       [0.04706538, 0.95293462],\n",
       "       [0.84630507, 0.15369493],\n",
       "       [0.9501416 , 0.0498584 ],\n",
       "       [0.47737147, 0.52262853],\n",
       "       [0.95243943, 0.04756057],\n",
       "       [0.87811145, 0.12188855],\n",
       "       [0.04769224, 0.95230776],\n",
       "       [0.32732571, 0.67267429],\n",
       "       [0.66434359, 0.33565641],\n",
       "       [0.40501189, 0.59498811],\n",
       "       [0.30641912, 0.69358088],\n",
       "       [0.81054841, 0.18945159],\n",
       "       [0.17842717, 0.82157283],\n",
       "       [0.89428706, 0.10571294],\n",
       "       [0.82820755, 0.17179245],\n",
       "       [0.43578135, 0.56421865],\n",
       "       [0.58698699, 0.41301301],\n",
       "       [0.92804124, 0.07195876],\n",
       "       [0.05875765, 0.94124235],\n",
       "       [0.32021075, 0.67978925],\n",
       "       [0.8941175 , 0.1058825 ],\n",
       "       [0.8369782 , 0.1630218 ],\n",
       "       [0.90136233, 0.09863767],\n",
       "       [0.84658742, 0.15341258],\n",
       "       [0.96501832, 0.03498168],\n",
       "       [0.15981955, 0.84018045],\n",
       "       [0.14478231, 0.85521769],\n",
       "       [0.68913754, 0.31086246],\n",
       "       [0.28520188, 0.71479812],\n",
       "       [0.15583949, 0.84416051],\n",
       "       [0.77820364, 0.22179636],\n",
       "       [0.58634111, 0.41365889],\n",
       "       [0.07764336, 0.92235664],\n",
       "       [0.86390692, 0.13609308],\n",
       "       [0.04145836, 0.95854164],\n",
       "       [0.82263664, 0.17736336],\n",
       "       [0.17339513, 0.82660487],\n",
       "       [0.91258133, 0.08741867],\n",
       "       [0.86219261, 0.13780739],\n",
       "       [0.82405858, 0.17594142],\n",
       "       [0.83421178, 0.16578822],\n",
       "       [0.58015092, 0.41984908],\n",
       "       [0.88209972, 0.11790028],\n",
       "       [0.86623706, 0.13376294],\n",
       "       [0.69519115, 0.30480885],\n",
       "       [0.90323094, 0.09676906],\n",
       "       [0.29585096, 0.70414904],\n",
       "       [0.29640453, 0.70359547],\n",
       "       [0.74291449, 0.25708551],\n",
       "       [0.36971951, 0.63028049],\n",
       "       [0.30106654, 0.69893346],\n",
       "       [0.82301712, 0.17698288],\n",
       "       [0.50827402, 0.49172598],\n",
       "       [0.15893133, 0.84106867],\n",
       "       [0.7537929 , 0.2462071 ],\n",
       "       [0.4744634 , 0.5255366 ],\n",
       "       [0.34117531, 0.65882469],\n",
       "       [0.74839272, 0.25160728],\n",
       "       [0.06460698, 0.93539302],\n",
       "       [0.88105153, 0.11894847],\n",
       "       [0.89631693, 0.10368307],\n",
       "       [0.89427166, 0.10572834],\n",
       "       [0.66430751, 0.33569249],\n",
       "       [0.42597869, 0.57402131],\n",
       "       [0.75602924, 0.24397076],\n",
       "       [0.65265572, 0.34734428],\n",
       "       [0.30631808, 0.69368192],\n",
       "       [0.74777515, 0.25222485],\n",
       "       [0.08635654, 0.91364346],\n",
       "       [0.89396314, 0.10603686],\n",
       "       [0.1748314 , 0.8251686 ],\n",
       "       [0.86834205, 0.13165795],\n",
       "       [0.163446  , 0.836554  ],\n",
       "       [0.86843673, 0.13156327],\n",
       "       [0.109679  , 0.890321  ],\n",
       "       [0.32853472, 0.67146528],\n",
       "       [0.87489815, 0.12510185],\n",
       "       [0.30640756, 0.69359244],\n",
       "       [0.91883964, 0.08116036],\n",
       "       [0.80667462, 0.19332538],\n",
       "       [0.65103481, 0.34896519],\n",
       "       [0.06985017, 0.93014983],\n",
       "       [0.8983305 , 0.1016695 ],\n",
       "       [0.86385741, 0.13614259],\n",
       "       [0.57717143, 0.42282857],\n",
       "       [0.86507887, 0.13492113],\n",
       "       [0.73505064, 0.26494936],\n",
       "       [0.80747883, 0.19252117],\n",
       "       [0.20833771, 0.79166229],\n",
       "       [0.09899277, 0.90100723],\n",
       "       [0.11535747, 0.88464253],\n",
       "       [0.31785302, 0.68214698],\n",
       "       [0.60171988, 0.39828012],\n",
       "       [0.89401333, 0.10598667],\n",
       "       [0.93322865, 0.06677135],\n",
       "       [0.70238977, 0.29761023],\n",
       "       [0.15882109, 0.84117891],\n",
       "       [0.87651582, 0.12348418],\n",
       "       [0.23258904, 0.76741096],\n",
       "       [0.33332394, 0.66667606],\n",
       "       [0.1490261 , 0.8509739 ],\n",
       "       [0.86505194, 0.13494806],\n",
       "       [0.43809403, 0.56190597],\n",
       "       [0.87749098, 0.12250902],\n",
       "       [0.90148588, 0.09851412],\n",
       "       [0.8941175 , 0.1058825 ],\n",
       "       [0.86390692, 0.13609308],\n",
       "       [0.88978843, 0.11021157],\n",
       "       [0.15089302, 0.84910698],\n",
       "       [0.86844447, 0.13155553],\n",
       "       [0.93028088, 0.06971912],\n",
       "       [0.86841498, 0.13158502],\n",
       "       [0.23093778, 0.76906222],\n",
       "       [0.27920995, 0.72079005],\n",
       "       [0.69627329, 0.30372671],\n",
       "       [0.89401077, 0.10598923],\n",
       "       [0.60063753, 0.39936247],\n",
       "       [0.8941175 , 0.1058825 ],\n",
       "       [0.36976697, 0.63023303],\n",
       "       [0.85431306, 0.14568694],\n",
       "       [0.55307649, 0.44692351],\n",
       "       [0.86390692, 0.13609308],\n",
       "       [0.05007403, 0.94992597],\n",
       "       [0.36473831, 0.63526169],\n",
       "       [0.8465892 , 0.1534108 ],\n",
       "       [0.18942893, 0.81057107],\n",
       "       [0.76952006, 0.23047994],\n",
       "       [0.85681607, 0.14318393],\n",
       "       [0.82002625, 0.17997375],\n",
       "       [0.73735885, 0.26264115],\n",
       "       [0.32674599, 0.67325401],\n",
       "       [0.84609576, 0.15390424],\n",
       "       [0.30640756, 0.69359244],\n",
       "       [0.2398058 , 0.7601942 ],\n",
       "       [0.27975779, 0.72024221],\n",
       "       [0.9107054 , 0.0892946 ],\n",
       "       [0.89421002, 0.10578998],\n",
       "       [0.56673855, 0.43326145],\n",
       "       [0.84658742, 0.15341258],\n",
       "       [0.89396314, 0.10603686],\n",
       "       [0.56931896, 0.43068104],\n",
       "       [0.31005013, 0.68994987],\n",
       "       [0.84658742, 0.15341258],\n",
       "       [0.77586774, 0.22413226],\n",
       "       [0.91010733, 0.08989267],\n",
       "       [0.88404563, 0.11595437],\n",
       "       [0.09872378, 0.90127622],\n",
       "       [0.90341228, 0.09658772],\n",
       "       [0.56815376, 0.43184624],\n",
       "       [0.89265058, 0.10734942],\n",
       "       [0.90069965, 0.09930035],\n",
       "       [0.69160108, 0.30839892],\n",
       "       [0.85053928, 0.14946072],\n",
       "       [0.87772289, 0.12227711],\n",
       "       [0.30640756, 0.69359244],\n",
       "       [0.28386682, 0.71613318],\n",
       "       [0.61878848, 0.38121152],\n",
       "       [0.80747184, 0.19252816],\n",
       "       [0.77929797, 0.22070203],\n",
       "       [0.54541876, 0.45458124],\n",
       "       [0.85787163, 0.14212837],\n",
       "       [0.81630077, 0.18369923],\n",
       "       [0.89410979, 0.10589021],\n",
       "       [0.35427766, 0.64572234],\n",
       "       [0.0840296 , 0.9159704 ],\n",
       "       [0.23541953, 0.76458047],\n",
       "       [0.6424328 , 0.3575672 ],\n",
       "       [0.72023497, 0.27976503],\n",
       "       [0.88698763, 0.11301237],\n",
       "       [0.82325902, 0.17674098],\n",
       "       [0.88408598, 0.11591402],\n",
       "       [0.82893923, 0.17106077],\n",
       "       [0.75762157, 0.24237843],\n",
       "       [0.60413768, 0.39586232],\n",
       "       [0.0646925 , 0.9353075 ],\n",
       "       [0.87516392, 0.12483608],\n",
       "       [0.21321506, 0.78678494],\n",
       "       [0.54988584, 0.45011416],\n",
       "       [0.81326175, 0.18673825],\n",
       "       [0.73012419, 0.26987581],\n",
       "       [0.3320352 , 0.6679648 ],\n",
       "       [0.53974534, 0.46025466],\n",
       "       [0.8465892 , 0.1534108 ],\n",
       "       [0.2959834 , 0.7040166 ],\n",
       "       [0.88697404, 0.11302596],\n",
       "       [0.58367288, 0.41632712],\n",
       "       [0.78801489, 0.21198511],\n",
       "       [0.90472396, 0.09527604],\n",
       "       [0.74087272, 0.25912728],\n",
       "       [0.84658742, 0.15341258],\n",
       "       [0.71437764, 0.28562236],\n",
       "       [0.90075671, 0.09924329],\n",
       "       [0.96851501, 0.03148499],\n",
       "       [0.03243387, 0.96756613],\n",
       "       [0.92638112, 0.07361888],\n",
       "       [0.28458243, 0.71541757],\n",
       "       [0.75762157, 0.24237843],\n",
       "       [0.32927944, 0.67072056],\n",
       "       [0.74654734, 0.25345266],\n",
       "       [0.19669973, 0.80330027],\n",
       "       [0.09046359, 0.90953641],\n",
       "       [0.7537929 , 0.2462071 ],\n",
       "       [0.67071834, 0.32928166],\n",
       "       [0.89937433, 0.10062567],\n",
       "       [0.2961815 , 0.7038185 ],\n",
       "       [0.71414337, 0.28585663],\n",
       "       [0.26936973, 0.73063027],\n",
       "       [0.89401589, 0.10598411],\n",
       "       [0.86390692, 0.13609308],\n",
       "       [0.436393  , 0.563607  ],\n",
       "       [0.98313418, 0.01686582],\n",
       "       [0.15891106, 0.84108894],\n",
       "       [0.19669973, 0.80330027],\n",
       "       [0.88672331, 0.11327669],\n",
       "       [0.06257894, 0.93742106],\n",
       "       [0.68160525, 0.31839475],\n",
       "       [0.87781415, 0.12218585],\n",
       "       [0.29881846, 0.70118154],\n",
       "       [0.09153057, 0.90846943],\n",
       "       [0.6893485 , 0.3106515 ],\n",
       "       [0.78372515, 0.21627485],\n",
       "       [0.04400748, 0.95599252],\n",
       "       [0.7254057 , 0.2745943 ],\n",
       "       [0.84018904, 0.15981096],\n",
       "       [0.1986963 , 0.8013037 ],\n",
       "       [0.04349231, 0.95650769],\n",
       "       [0.45584257, 0.54415743],\n",
       "       [0.7310863 , 0.2689137 ],\n",
       "       [0.72746776, 0.27253224],\n",
       "       [0.94080689, 0.05919311],\n",
       "       [0.86390692, 0.13609308],\n",
       "       [0.85152808, 0.14847192],\n",
       "       [0.36488219, 0.63511781],\n",
       "       [0.36000222, 0.63999778],\n",
       "       [0.77576577, 0.22423423],\n",
       "       [0.23201691, 0.76798309],\n",
       "       [0.87803295, 0.12196705],\n",
       "       [0.88443909, 0.11556091],\n",
       "       [0.83238518, 0.16761482],\n",
       "       [0.91735194, 0.08264806],\n",
       "       [0.47893646, 0.52106354],\n",
       "       [0.16381328, 0.83618672],\n",
       "       [0.86805249, 0.13194751],\n",
       "       [0.85251206, 0.14748794],\n",
       "       [0.95556123, 0.04443877],\n",
       "       [0.07604825, 0.92395175],\n",
       "       [0.84434441, 0.15565559],\n",
       "       [0.12072453, 0.87927547],\n",
       "       [0.8717097 , 0.1282903 ],\n",
       "       [0.86893137, 0.13106863],\n",
       "       [0.05842742, 0.94157258],\n",
       "       [0.85165173, 0.14834827],\n",
       "       [0.0492908 , 0.9507092 ],\n",
       "       [0.47342203, 0.52657797],\n",
       "       [0.63845842, 0.36154158],\n",
       "       [0.63113423, 0.36886577],\n",
       "       [0.79389076, 0.20610924],\n",
       "       [0.57594246, 0.42405754],\n",
       "       [0.30642778, 0.69357222],\n",
       "       [0.28991466, 0.71008534],\n",
       "       [0.30640756, 0.69359244],\n",
       "       [0.08859209, 0.91140791],\n",
       "       [0.35994188, 0.64005812],\n",
       "       [0.89396314, 0.10603686],\n",
       "       [0.0593078 , 0.9406922 ],\n",
       "       [0.91640648, 0.08359352],\n",
       "       [0.89396314, 0.10603686],\n",
       "       [0.88897417, 0.11102583]])"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j55fp5GJeMHR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2021_02_11_214_guided_project_notes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
